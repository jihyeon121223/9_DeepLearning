{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34c44d-68ad-451c-9019-30e6383285bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "케라스 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1872a462-e58d-4e1e-9d34-414cd1358808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모듈임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8d3ddf-fced-475b-bdf6-6c49a2d214db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#집분석 \n",
    "\n",
    "#각각의 데이터 셋 불러와서 학습률 높이기\n",
    "(X_train,y_train), (X_test,y_test) = boston_housing.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf3a28c-7bcd-4b1d-8a5d-5c6cd6d3fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5499f70-b211-426f-a422-a312a28b6a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7747447c-be46-4988-88f4-409f7cb9201d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 23:10:58.661230: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 6s 236ms/step - loss: 2.0420 - accuracy: 0.5278\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 5s 227ms/step - loss: 1.0602 - accuracy: 0.7476\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 5s 228ms/step - loss: 0.6256 - accuracy: 0.8441\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 5s 224ms/step - loss: 0.3818 - accuracy: 0.9027\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 5s 226ms/step - loss: 0.2377 - accuracy: 0.9401\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 5s 234ms/step - loss: 0.1708 - accuracy: 0.9522\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 6s 243ms/step - loss: 0.1371 - accuracy: 0.9567\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 5s 230ms/step - loss: 0.1167 - accuracy: 0.9575\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.1008 - accuracy: 0.9591\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.0916 - accuracy: 0.9607\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 5s 224ms/step - loss: 0.0920 - accuracy: 0.9597\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0813 - accuracy: 0.9597\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 5s 227ms/step - loss: 0.0827 - accuracy: 0.9594\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0759 - accuracy: 0.9615\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0744 - accuracy: 0.9593\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0748 - accuracy: 0.9598\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 5s 232ms/step - loss: 0.0701 - accuracy: 0.9615\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0708 - accuracy: 0.9619\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0681 - accuracy: 0.9607\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0686 - accuracy: 0.9608\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 6s 240ms/step - loss: 0.0660 - accuracy: 0.9619\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0659 - accuracy: 0.9603\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.0649 - accuracy: 0.9623\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 0.0648 - accuracy: 0.9610\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0627 - accuracy: 0.9607\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 0.0639 - accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0632 - accuracy: 0.9638\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 5s 217ms/step - loss: 0.0608 - accuracy: 0.9620\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 5s 210ms/step - loss: 0.0620 - accuracy: 0.9636\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.0609 - accuracy: 0.9621\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 5s 209ms/step - loss: 0.0607 - accuracy: 0.9623\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 5s 209ms/step - loss: 0.0601 - accuracy: 0.9629\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 5s 210ms/step - loss: 0.0609 - accuracy: 0.9620\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0595 - accuracy: 0.9609\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 5s 224ms/step - loss: 0.0583 - accuracy: 0.9623\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 5s 213ms/step - loss: 0.0576 - accuracy: 0.9628\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0573 - accuracy: 0.9631\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0576 - accuracy: 0.9633\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0576 - accuracy: 0.9643\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.0585 - accuracy: 0.9621\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 5s 225ms/step - loss: 0.0610 - accuracy: 0.9625\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 5s 228ms/step - loss: 0.0576 - accuracy: 0.9620\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 5s 227ms/step - loss: 0.0570 - accuracy: 0.9624\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 5s 224ms/step - loss: 0.0561 - accuracy: 0.9629\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 5s 231ms/step - loss: 0.0570 - accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 5s 228ms/step - loss: 0.0560 - accuracy: 0.9624\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 5s 228ms/step - loss: 0.0552 - accuracy: 0.9646\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0568 - accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 0.0566 - accuracy: 0.9627\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 5s 233ms/step - loss: 0.0561 - accuracy: 0.9636\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 0.0560 - accuracy: 0.9638\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0558 - accuracy: 0.9642\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0575 - accuracy: 0.9633\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 5s 211ms/step - loss: 0.0571 - accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.0551 - accuracy: 0.9634\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 5s 229ms/step - loss: 0.0550 - accuracy: 0.9629\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0551 - accuracy: 0.9637\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 5s 216ms/step - loss: 0.0577 - accuracy: 0.9619\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0609 - accuracy: 0.9610\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.0581 - accuracy: 0.9645\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0574 - accuracy: 0.9637\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0579 - accuracy: 0.9607\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 5s 226ms/step - loss: 0.0572 - accuracy: 0.9650\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 5s 227ms/step - loss: 0.0582 - accuracy: 0.9623\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0678 - accuracy: 0.9601\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0814 - accuracy: 0.9567\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.0796 - accuracy: 0.9598\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 5s 226ms/step - loss: 0.0952 - accuracy: 0.9565\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 5s 225ms/step - loss: 0.0984 - accuracy: 0.9545\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 5s 213ms/step - loss: 0.0920 - accuracy: 0.9542\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 5s 237ms/step - loss: 0.0733 - accuracy: 0.9598\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 5s 234ms/step - loss: 0.0654 - accuracy: 0.9607\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 5s 214ms/step - loss: 0.0586 - accuracy: 0.9616\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 5s 211ms/step - loss: 0.0579 - accuracy: 0.9628\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 5s 214ms/step - loss: 0.0562 - accuracy: 0.9626\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 5s 216ms/step - loss: 0.0544 - accuracy: 0.9614\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0537 - accuracy: 0.9620\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 6s 239ms/step - loss: 0.0533 - accuracy: 0.9644\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 5s 238ms/step - loss: 0.0539 - accuracy: 0.9634\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.0525 - accuracy: 0.9621\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0535 - accuracy: 0.9626\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0538 - accuracy: 0.9624\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 5s 222ms/step - loss: 0.0542 - accuracy: 0.9633\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0531 - accuracy: 0.9629\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.0534 - accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 5s 212ms/step - loss: 0.0530 - accuracy: 0.9629\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 5s 219ms/step - loss: 0.0521 - accuracy: 0.9645\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 6s 273ms/step - loss: 0.0518 - accuracy: 0.9628\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 6s 244ms/step - loss: 0.0518 - accuracy: 0.9649\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 6s 247ms/step - loss: 0.0519 - accuracy: 0.9635\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 6s 245ms/step - loss: 0.0523 - accuracy: 0.9608\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 5s 226ms/step - loss: 0.0521 - accuracy: 0.9636\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 5s 221ms/step - loss: 0.0528 - accuracy: 0.9654\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.0523 - accuracy: 0.9649\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 5s 223ms/step - loss: 0.0528 - accuracy: 0.9636\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 5s 215ms/step - loss: 0.0516 - accuracy: 0.9650\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 5s 218ms/step - loss: 0.0527 - accuracy: 0.9624\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 5s 211ms/step - loss: 0.0520 - accuracy: 0.9635\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 5s 220ms/step - loss: 0.0515 - accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 5s 224ms/step - loss: 0.0511 - accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1eee740880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#뉴스텍스트분석 \n",
    "\n",
    "#각각의 데이터 셋 불러와서 학습률 높이기\n",
    "from keras.datasets import reuters\n",
    "(X_train,y_train),(X_test,y_test) = reuters.load_data(num_words=10000)\n",
    "#각각 불러온거 모아주기\n",
    "X = np.concatenate([X_train,X_test])\n",
    "y = np.concatenate([y_train,y_test])\n",
    "#불러온 정보의 인덱스만 가져오기\n",
    "word_index = reuters.get_word_index()\n",
    "#자리바꾸기 ??? 왜함 ???\n",
    "index_word = {v:k for k,v in word_index.items()}\n",
    "\n",
    "doc = []\n",
    "for i in X_train:\n",
    "    tmp = []\n",
    "    for j in range(len(i)):\n",
    "        if i[j] < 30980:\n",
    "            tmp.append(index_word[i[j]])\n",
    "            sentence = ' '.join(tmp)\n",
    "    doc.append(sentence)\n",
    "\n",
    "#글자쪼개기\n",
    "data = pd.DataFrame(doc,columns=['text'])\n",
    "data['category'] = y_train\n",
    "\n",
    "xx = []\n",
    "for i in data.text.str.split(' '):\n",
    "    # print(i)\n",
    "    xx.extend(i)    \n",
    "aa = np.unique(np.array(xx))\n",
    "word_index = {k:v for k,v in enumerate(list(aa))}\n",
    "index_word = {v:k for k,v in word_index.items()}\n",
    "\n",
    "#글자쪼개기를 함수로 만들기\n",
    "# def contexts_to_index(sentence,index_word):\n",
    "#     if \" \" in sentence:\n",
    "#         tmp = []\n",
    "#         word_list = sentence.split()\n",
    "#         for word in word_list:\n",
    "#             tmp.append(index_word[word])\n",
    "#         return tmp\n",
    "#     else:\n",
    "#         return index_word[sentence]\n",
    "\n",
    "# #전처리\n",
    "# len(data.text[[0]].str.split(' '))\n",
    "# list(data.text[[0]].str.split(' '))\n",
    "# data.text[[0]].str.split(' ')[0]\n",
    "# data = data.replace('\\n','')\n",
    "\n",
    "def make_index(x):\n",
    "    x = x.split(' ')\n",
    "    tmp = []\n",
    "    for i in x:\n",
    "        try:\n",
    "            tmp.append(index_word1[i])\n",
    "        except KeyError:\n",
    "            tmp.append(7)\n",
    "    return tmp\n",
    "\n",
    "#정수 인덱스를 원핫인코딩\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
    "    return results\n",
    "\n",
    "#모델\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train = vectorize_sequences(X_train) #처리시켜줘\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024,activation='relu',input_shape=(input_shape,)))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(output_shape,activation='softmax'))\n",
    "\n",
    "#모델설정\n",
    "opt = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "model.compile(optimizer=opt,\n",
    "             loss=loss,\n",
    "             metrics=metrics)\n",
    "\n",
    "#학습\n",
    "epochs = 100\n",
    "batch_size = 400\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ca1e5-8097-4630-a63b-3506c24ad8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kbu",
   "language": "python",
   "name": "kbu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
