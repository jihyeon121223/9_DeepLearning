{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55254c2e-b0b7-49af-abc8-cb5fdff98687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from layers import MultiLayer\n",
    "from layers import Relu, Affine, SoftmaxWithLoss, Sigmoid\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a9ee1e-857b-4c41-a3cf-1ad6e98f325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one(x):\n",
    "    if x.ndim == 1: \n",
    "        t = np.zeros((x.size,np.unique(x).size))\n",
    "        for i in range(t.shape[0]):\n",
    "            t[i,x[i]]=1\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024bbd44-7551-4def-8962-cb06c4d0c4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLayer:\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.hidden_size.insert(0,self.input_size)\n",
    "        self.hidden_size.append(self.output_size)\n",
    "        self.W = {}\n",
    "        for i in range(len(hidden_size)-1):\n",
    "            w_key = 'W'+str(i+1)\n",
    "            b_key = 'b'+str(i+1)\n",
    "            self.W[w_key] = np.random.randn(hidden_size[i],hidden_size[i+1])\n",
    "            self.W[b_key] = np.random.randn(hidden_size[i+1])\n",
    "            \n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(int(len(self.W)/2-1)):\n",
    "            j = i*2 \n",
    "            key1 = 'Affine'+str(i+1)\n",
    "            key2 = 'Relu'+str(i+1)\n",
    "            w = list(self.W.keys())[j]\n",
    "            b = list(self.W.keys())[j+1]\n",
    "            self.layers[key1] = Affine(self.W[w],self.W[b])\n",
    "            self.layers[key2] = Relu()\n",
    "        \n",
    "        last_num = str(int(len(self.W)/2))\n",
    "        self.layers['Affine'+last_num] = Affine(self.W['W'+last_num],self.W['b'+last_num])\n",
    "        self.Lastlayer = SoftmaxWithLoss()\n",
    "        self.loss_val = []\n",
    "        self.acc_val = []\n",
    "    \n",
    "    #def summary(self):\n",
    "        \n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        loss = self.Lastlayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def gradient(self,x,t):\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.Lastlayer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        grads = {}\n",
    "        layer_number = int(len(self.layers.keys())/2)\n",
    "        \n",
    "        for i in range(1,layer_number):\n",
    "            grads['W'+str(i)] = self.layers['Affine'+str(i)].dW\n",
    "            grads['b'+str(i)] = self.layers['Affine'+str(i)].db\n",
    "            \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = np.argmax(self.predict(x),axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        acc = np.sum(y==t)/y.size\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x,t,x_val,t_val):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            for key in grads.keys():\n",
    "                self.W[key] -=  lr*grads[key]\n",
    "            print(\"epoch \",epoch,\":val_loss===========\",self.loss(x_val,t_val),\"val_acc:========\",self.accuracy(x_val,t_val))\n",
    "            self.loss_val.append(self.loss(x_val,t_val))\n",
    "            self.acc_val.append(np.round(self.accuracy(x_val,t_val),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f9eda8-a16d-42ee-825b-0df3e359eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "X = X.astype(np.float32).values/255.\n",
    "y = y.astype(np.int32).values\n",
    "y = make_one(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test, test_size=.5)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = [100,256,100]\n",
    "output_size = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7482a8a9-ba59-49c3-844b-a66d19cedf4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :val_loss=========== 14.026076066998575 val_acc:======== 0.12921428571428573\n",
      "epoch  1 :val_loss=========== 13.442249349226264 val_acc:======== 0.16557142857142856\n",
      "epoch  2 :val_loss=========== 12.837210528861236 val_acc:======== 0.20264285714285715\n",
      "epoch  3 :val_loss=========== 12.189550916520544 val_acc:======== 0.24285714285714285\n",
      "epoch  4 :val_loss=========== 11.65004034314038 val_acc:======== 0.27614285714285713\n",
      "epoch  5 :val_loss=========== 11.124946123607865 val_acc:======== 0.3087857142857143\n",
      "epoch  6 :val_loss=========== 10.634768645874578 val_acc:======== 0.3392142857142857\n",
      "epoch  7 :val_loss=========== 10.261029710926197 val_acc:======== 0.36228571428571427\n",
      "epoch  8 :val_loss=========== 9.917983014517079 val_acc:======== 0.38371428571428573\n",
      "epoch  9 :val_loss=========== 9.632331868379387 val_acc:======== 0.4012142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3905"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayer(input_size,hidden_size,output_size)\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "model.fit(epochs,lr,X_train,y_train,X_val,y_val)\n",
    "model.accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a085ab-eb90-43dc-83ae-e38207335eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#핏에 배치 추가 :: 방금 한거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bfaacc0-78bd-4193-b381-a34d2f1b20b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayer:\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.hidden_size.insert(0,self.input_size)\n",
    "        self.hidden_size.append(self.output_size)\n",
    "        self.W = {}\n",
    "        for i in range(len(hidden_size)-1):\n",
    "            w_key = 'W'+str(i+1)\n",
    "            b_key = 'b'+str(i+1)\n",
    "            self.W[w_key] = np.random.randn(hidden_size[i],hidden_size[i+1])\n",
    "            self.W[b_key] = np.random.randn(hidden_size[i+1])\n",
    "            \n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(int(len(self.W)/2-1)):\n",
    "            j = i*2 \n",
    "            key1 = 'Affine'+str(i+1)\n",
    "            key2 = 'Relu'+str(i+1)\n",
    "            w = list(self.W.keys())[j]\n",
    "            b = list(self.W.keys())[j+1]\n",
    "            self.layers[key1] = Affine(self.W[w],self.W[b])\n",
    "            self.layers[key2] = Relu()\n",
    "        \n",
    "        last_num = str(int(len(self.W)/2))\n",
    "        self.layers['Affine'+last_num] = Affine(self.W['W'+last_num],self.W['b'+last_num])\n",
    "        self.Lastlayer = SoftmaxWithLoss()\n",
    "        self.loss_val = []\n",
    "        self.acc_val = []\n",
    "    \n",
    "    #def summary(self):\n",
    "        \n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        loss = self.Lastlayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def gradient(self,x,t):\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.Lastlayer.backward(dout)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        grads = {}\n",
    "        layer_number = int(len(self.layers.keys())/2)\n",
    "        \n",
    "        for i in range(1,layer_number):\n",
    "            grads['W'+str(i)] = self.layers['Affine'+str(i)].dW\n",
    "            grads['b'+str(i)] = self.layers['Affine'+str(i)].db\n",
    "            \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = np.argmax(self.predict(x),axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        acc = np.sum(y==t)/y.size\n",
    "        return acc\n",
    "    \n",
    "\n",
    "    def fit_sgd(self,epochs,batch_size,lr,x,t,x_val,t_val): #미니배치\n",
    "        if divmod(x.shape[0],batch_size)[1] > 0:\n",
    "            batch = divmod(x.shape[0],batch_size)[0] + 1\n",
    "        else:\n",
    "            batch = divmod(x.shape[0],batch_size)[0]\n",
    "        for epoch in range(epochs):\n",
    "            if epoch == 0:\n",
    "                start = 0\n",
    "            end = start + batch_size\n",
    "            if epoch == epochs-1 and divmod(x.shape[0],batch_size)[1] != 0:\n",
    "                end = start+divmod(x.shape[0],batch_size)[1]\n",
    "            x_tmp = x[start:end,:]\n",
    "            t_tmp = t[start:end,:]\n",
    "            start = end\n",
    "            for i in range(batch):\n",
    "                grads = self.gradient(x_tmp,t_tmp)\n",
    "            for key in grads.keys():\n",
    "                self.W[key] -=  lr*grads[key]\n",
    "            if epoch % 20 == 0:\n",
    "                print(\"epoch \",epoch,\":val_loss===========\",self.loss(x_val,t_val),\"val_acc:========\",self.accuracy(x_val,t_val))\n",
    "                self.loss_val.append(self.loss(x_val,t_val))\n",
    "                self.acc_val.append(np.round(self.accuracy(x_val,t_val),2))\n",
    "                \n",
    "                \n",
    "    def fit_gd(self,epochs,lr,x,t,x_val,t_val): #풀배치\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            for key in grads.keys():\n",
    "                self.W[key] -=  lr*grads[key]\n",
    "            if epoch % 20 == 0:\n",
    "                    print(\"epoch \",epoch,\":val_loss===========\",self.loss(x_val,t_val),\"val_acc:========\",self.accuracy(x_val,t_val))\n",
    "                    self.loss_val.append(self.loss(x_val,t_val))\n",
    "                    self.acc_val.append(np.round(self.accuracy(x_val,t_val),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd6e60e-408c-4a10-a983-99f36747b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "X = X.astype(np.float32).values/255.\n",
    "y = y.astype(np.int32).values\n",
    "y = make_one(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c7a9929-1cc6-4c74-8b26-b945a04dc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1]\n",
    "hidden_size = [100,150]\n",
    "output_size = y.shape[1]\n",
    "model = MultiLayer(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf760107-b399-43da-b949-932d1a1beccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :val_loss=========== 14.16628765225076 val_acc:======== 0.11871428571428572\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "model.fit_gd(epochs,lr,X_train,y_train,X_val,y_val)\n",
    "# model.accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e891d7b-3241-4dce-8c22-c80cc5f66507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 :val_loss=========== 13.816012001582958 val_acc:======== 0.13907142857142857\n",
      "epoch  20 :val_loss=========== 13.288338969846968 val_acc:======== 0.17064285714285715\n",
      "epoch  40 :val_loss=========== 12.74877914908254 val_acc:======== 0.20285714285714285\n",
      "epoch  60 :val_loss=========== 12.375286269109766 val_acc:======== 0.22557142857142856\n",
      "epoch  80 :val_loss=========== 12.070652104167394 val_acc:======== 0.24271428571428572\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 1e-3\n",
    "batch_size = 100\n",
    "model.fit_sgd(batch_size,epochs,lr,X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46a0e9-7511-4303-a092-a9f790fa6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 까지 툴안쓰고 넘파이로만 돌리기 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3755b3f-ca3d-41da-a701-9a15b4f4a72b",
   "metadata": {},
   "source": [
    "ppt.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30733a-25b6-478c-b1a3-92e6d738b3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef34ef8-43fc-4807-bf53-a90d98b83a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee2270d-df27-4970-bb74-4c2e9c176882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self,lr=1e-3):\n",
    "        self.lr = lr\n",
    "    \n",
    "    def minimize(self, w, grads):\n",
    "        for key in w.keys():\n",
    "            w[key] -=  self.lr*grads[key]\n",
    "            \n",
    "class Momentum:\n",
    "    def __init__(self,lr=1e-3,m=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = m\n",
    "        self.v = None\n",
    "    \n",
    "    def minimize(self,w,grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for k,v in w.items():\n",
    "                self.v[k] = np.zeros_like(v)\n",
    "        for key in w.keys():\n",
    "            self.v[key] = self.momentum + self.v[key] - self.lr*grads[key]\n",
    "            w[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5daf9a6-da90-4a99-957a-a36c1b11e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Momentum(lr=1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f90b36-7058-422a-b121-4427ef41b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    grads = model.gradient(X_train,y_train)\n",
    "    optimizer.minimize(model.W,grads)\n",
    "    if epoch % 20 == 0:\n",
    "        print(\"epoch \",epoch,\":val_loss===========\",model.loss(X_test,y_test),\"val_acc:========\",model.accuracy(X_test,y_test))\n",
    "        model.loss_val.append(model.loss(X_test,y_test))\n",
    "        model.acc_val.append(np.round(model.accuracy(X_test,y_test),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b14259-b57e-4bce-85c6-3b6b9b769c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c122ed3d-7e35-4017-860f-93a21fda840a",
   "metadata": {},
   "source": [
    "### 코딩하면서 테스트 해본것들"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6006ee4-1294-4769-af7a-13ddb1d46b5c",
   "metadata": {},
   "source": [
    "# def fit_sgd 테스트\n",
    "\n",
    "X.shape[0]\n",
    "batch_size = 1001\n",
    "if divmod(X.shape[0],batch_size)[1] > 0:\n",
    "    epochs = divmod(X.shape[0],batch_size)[0] + 1\n",
    "else:\n",
    "    epochs = divmod(X.shape[0],batch_size)[0]\n",
    "for epoch in range(epochs):\n",
    "    if epoch == 0:\n",
    "        start = 0\n",
    "    end = start + batch_size\n",
    "    if epoch == epochs-1 and divmod(X.shape[0],batch_size)[1] != 0:\n",
    "        end = start+divmod(X.shape[0],batch_size)[1]\n",
    "    print(epoch,start,end)\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "raw",
   "id": "813c0976-2784-41e2-b86e-d43461485253",
   "metadata": {},
   "source": [
    "divmod(X_train.shape[0],batch_size)[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28a2d24e-c4c0-476e-8622-e1dca0f5737e",
   "metadata": {},
   "source": [
    "X_train[0:batch_size]\n",
    "X_train[batch_size:2*batch_size]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6c076df-a364-4201-8f63-5e0b27ef288d",
   "metadata": {},
   "source": [
    "batch_size = 10000\n",
    "X_train.shape[0]//batch_size\n",
    "X_train.shape[0]%batch_size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdc9fe45-b3dc-4fa2-9e41-fd74edc1a871",
   "metadata": {},
   "source": [
    "grads = model.gradient(X_train,y_train)\n",
    "\n",
    "for i in grads.keys():\n",
    "    print(i,\"====\",grads[i].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
