{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ec31807a-5df0-4f40-a633-c638c93310cf",
   "metadata": {},
   "source": [
    "twolayernet2 test\n",
    "#내일 옵티마이저랑 이거랑 멀티레이어 할거임 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55531657-0383-4c07-ab35-48d9d4ee6ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from layers import TwoLayerNet, TwoLayerNet2\n",
    "from collections import OrderedDict\n",
    "from layers import Relu, SoftmaxWithLoss, Affine\n",
    "from loss import cross_entropy_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35829d-4db3-4560-b80d-f1932be7873d",
   "metadata": {},
   "source": [
    "# 꽃데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea875166-0314-43fd-a020-94ba1ce1bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris #꽃잎의 각 부분의 너비와 길이등을 측정한 데이터 150개의 레코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ceaf18-d58f-4cd2-aa1c-8a7d914debb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_iris()['data'] #[5.1, 3.5, 1.4, 0.2]... 으로 이루어진 행렬\n",
    "y = load_iris()['target'] #0000..11111...2222 으로 이루어진 리스트\n",
    "t = np.zeros((y.size,np.unique(y).size)) #[1., 0., 0.] 해당 부분만 1로 이루어진 원핫인코딩\n",
    "for i in range(t.shape[0]):  #shape[0], shape[1]: 전체 행의 갯수와 열의 갯수\n",
    "    t[i,y[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e02e6d-8a48-4236-acbe-5154ccc7de64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X.shape[1] #X의 열갯수\n",
    "hidden_size = 5 #숨은 레이어 몇개 넣을건지 정해줌\n",
    "output_size = t.shape[1] #t의 열갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028fdfcc-308c-458c-a8d2-45b645addc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TwoLayerNet(input_size,hidden_size,output_size) #한방향으로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9c678b-04e5-4936-9043-956786243a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TwoLayerNet2(input_size,hidden_size,output_size) #거꾸로도 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97be2133-a10e-4cf0-9f93-160608106a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.predict(X).shape #가중치, 상수b로 더하고, -는 0으로, 나온값이 결과 값과 같을 확률\n",
    "grads1 = model1.numerical_gradient(X,t) #각 점에서의 기울기를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf237208-82b3-4c6d-8871-bcb7873a3ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.88072799, 0.        , 0.        , 0.        , 0.72505658],\n",
       "        [0.45799779, 0.        , 0.        , 0.        , 0.34002752],\n",
       "        [0.46665996, 0.        , 0.        , 0.        , 0.48902087],\n",
       "        [0.10499866, 0.        , 0.        , 0.        , 0.14603627]]),\n",
       " 'b1': array([1.65112718e-09, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.23128649e-09]),\n",
       " 'W2': array([[ 1.55982093, -1.07408421, -0.48550914],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.28961389, -0.06803845,  0.35776929]]),\n",
       " 'b2': array([ 4.28424141e-09, -3.15786873e-09, -1.12637268e-09])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads1 #값의 변화가 거의 알아보기 힘듦 = 오래 많이 돌려야 해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265413b4-cf98-46bc-a369-08378341e6e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.predict(X).shape\n",
    "grads2 = model2.gradient(X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e63fcf-3a97-4d34-a798-946e72c02e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.81909302e+00,  0.00000000e+00,  4.77022965e+00,\n",
       "          1.01836617e+00, -5.14836405e-02],\n",
       "        [ 1.24567549e+00,  0.00000000e+00,  2.68252605e+00,\n",
       "          5.03663839e-01, -3.87957290e-02],\n",
       "        [ 5.31265080e-01,  0.00000000e+00,  2.77140274e+00,\n",
       "          7.54512537e-01, -1.24439131e-02],\n",
       "        [ 8.93920265e-02,  0.00000000e+00,  8.81097810e-01,\n",
       "          2.64515983e-01, -1.70798806e-03]]),\n",
       " 'b1': array([ 0.36338255,  0.        ,  0.83284692,  0.16361276, -0.00975993]),\n",
       " 'W2': array([[-1.03462027e+00,  1.03462013e+00,  1.47200843e-07],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "        [-2.69468598e+00,  6.23139481e+00, -3.53670883e+00],\n",
       "        [-2.90655429e+00,  4.77160841e+00, -1.86505412e+00],\n",
       "        [-1.37961301e-03,  1.37961296e-03,  4.96600811e-11]]),\n",
       " 'b2': array([-0.33333314,  0.66666632, -0.33333318])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads2 #grad1과 비교했을 때 값의 변화가 약간은 알아볼 정도 = 많이 안돌려도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03eaaf98-c2c1-4022-8f06-141121217bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3290092 , -0.3673433 ,  1.20161643,  0.32560007,  0.05276098],\n",
       "       [ 0.19500194, -0.5883821 ,  0.80853856,  2.02189401,  0.27187539],\n",
       "       [-0.32503978,  0.44488989,  0.17403802, -0.55999547, -0.68496807],\n",
       "       [-2.26670893,  0.33186214,  0.15751204, -0.24229152, -1.33106051]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.W['W1'] #첫번째 가중치 값 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7debdc2-47ca-444a-b44a-8937b40de99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.451242436136154"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.loss(X,t) #예측값와 실제값에 대한 오차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3783529-89db-40fd-9028-52e3076d8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2에서 def fit 만들기 완료 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75632e8e-1992-4ad3-9d76-4348c10fcb58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 ============== 10.357506717223439 accuracy:============= 0.3333333333333333\n",
      "epoch 1 ============== 10.303408896039395 accuracy:============= 0.3333333333333333\n",
      "epoch 2 ============== 10.244380282468674 accuracy:============= 0.3333333333333333\n",
      "epoch 3 ============== 10.180414850321359 accuracy:============= 0.3333333333333333\n",
      "epoch 4 ============== 10.111570972634992 accuracy:============= 0.3333333333333333\n",
      "epoch 5 ============== 10.037970683739877 accuracy:============= 0.3333333333333333\n",
      "epoch 6 ============== 9.959796250402887 accuracy:============= 0.3333333333333333\n",
      "epoch 7 ============== 9.877284211383849 accuracy:============= 0.3333333333333333\n",
      "epoch 8 ============== 9.79071728379426 accuracy:============= 0.3333333333333333\n",
      "epoch 9 ============== 9.700414749025496 accuracy:============= 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "epochs = 10  #1에폭은 학습에서 훈련데이터를 모두 소진했을 때의 횟수\n",
    "lr = 1e-3  #Gradient decent 알고리즘을 적용시킬 때, 얼마만큼 경사각을 내려갈 것인지\n",
    "model2.fit(epochs,lr,X,t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cb766c3-6720-4730-86e6-510a1724ac10",
   "metadata": {},
   "source": [
    "#내가 난 오류 참고 https://wooono.tistory.com/425\n",
    "layers.py 에 고친부분\n",
    "self.loss_val.extend([self.loss(x,t)])\n",
    "self.acc_val.extend([np.round(self.accuracy(x,t)),2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "079a227a-0323-48d3-9083-1ff69a01f5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.406742291309993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#떨어졌는지 확인\n",
    "model2.loss(X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae7afbb-ca35-4422-8b1d-ef83df18e864",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,784) and (4,5) not aligned: 784 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/3340057537.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\수업노트\\이강욱강사\\9.DeepLearning\\layers.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#x업데이트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\수업노트\\이강욱강사\\9.DeepLearning\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#=predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,784) and (4,5) not aligned: 784 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.argmax(model2.predict(X[[1],:])) #np.argmax(t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b88d3-5e3f-43a2-89a3-0cdbed2f4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.W['W1'] -= 0.001*grads2['W1']\n",
    "model2.W['b1'] -= 0.001*grads2['b1']\n",
    "model2.W['W2'] -= 0.001*grads2['W2']\n",
    "model2.W['b2'] -= 0.001*grads2['b2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd1a6c-7c07-4764-8644-3e7b56830381",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(model2.loss_val)),model2.loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516323bf-1d70-4b09-a1bc-c8b80f3f7895",
   "metadata": {},
   "source": [
    "# 손글씨 사진 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e415ccb-22ba-4a16-8fbe-0aa5c097e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f57c11e-d4a7-4932-8d29-7753f7d9b488",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f520d696-aa98-4a61-b842-db7ba4f3e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist['data'] #[한값만 흰색깔784? 데이터 나머지 검정색0]\n",
    "y = mnist['target'] #흰색이 몇개 들었나 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae80c05-743b-4e61-aaf8-d539fbf73c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = X.values #키 밸류 중 밸류뽑을거야\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96030737-6a87-486e-a63c-a371165b2077",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "496e58ec-2720-460a-b0e1-2bc84ebf0ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)\n",
    "t = np.zeros((y.size,np.unique(y).size))\n",
    "for i in range(t.shape[0]):\n",
    "    t[i,y[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f57fd6-26aa-44fe-b091-288a7692963b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08287142857142857"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = X.shape[1]\n",
    "hidden_size = 100\n",
    "output_size = t.shape[1]\n",
    "model3 = TwoLayerNet2(input_size,hidden_size,output_size)\n",
    "model3.accuracy(X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4211c70e-4aaa-48dd-a453-5d927fae2661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "epoch 0 ============== 13.66589563455476 accuracy:============= 0.15198571428571428\n",
      "epoch 1 ============== 11.85654171680206 accuracy:============= 0.26421428571428573\n",
      "epoch 2 ============== 11.085244755934877 accuracy:============= 0.31197142857142857\n",
      "epoch 3 ============== 10.08772378062463 accuracy:============= 0.3739142857142857\n",
      "epoch 4 ============== 9.158933024498307 accuracy:============= 0.43147142857142856\n",
      "epoch 5 ============== 8.219522945853258 accuracy:============= 0.48964285714285716\n",
      "epoch 6 ============== 7.44752300180083 accuracy:============= 0.5376\n",
      "epoch 7 ============== 6.8210416604959825 accuracy:============= 0.5764857142857143\n",
      "epoch 8 ============== 6.718866720315721 accuracy:============= 0.5826714285714286\n",
      "epoch 9 ============== 6.267842304298431 accuracy:============= 0.6108142857142858\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t) #수치적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c352aa2-4b39-4a6a-8181-64ed320b10aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.show(np.arange(len(model3.loss_val)),model3.loss_val)\n",
    "plt.show(np.arange(len(model3.acc_val)),model3.acc_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6ab4fe4-3a9d-426e-91aa-3bf724f848b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet3:     #가중치가 0일때\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.zeros((input_size,hidden_size))\n",
    "        self.W['b1'] = np.zeros(hidden_size)\n",
    "        self.W['W2'] = np.zeros((hidden_size,output_size))\n",
    "        self.W['b2'] = np.zeros(output_size)\n",
    "        self.loss_val = []\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "        self.loss_val=[]\n",
    "        self.acc_val=[]\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): #x업데이트\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        # loss = cross_entropy_error(y,t) #미분하려고 구한거(수치적) >> 해석적으로 쓰려고 class만듦 :forwardmax, backwardmax\n",
    "        loss = self.lastLayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def numerical_gradient(self,x,t):\n",
    "        f = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(f, self.W['W1'])\n",
    "        grads['b1'] = numerical_gradient(f, self.W['b1'])\n",
    "        grads['W2'] = numerical_gradient(f, self.W['W2'])\n",
    "        grads['b2'] = numerical_gradient(f, self.W['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t): #backward시켜주는거 #맨 마지막loss부터 거꾸로 #grad(기울기)를 원래 값에서 빼주면 학습이 되는것이기 때문\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout) #미분값\n",
    "        layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout) \n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = sum(y == t)/x.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x,t):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            self.W['W1'] -= lr*grads['W1']\n",
    "            self.W['b1'] -= lr*grads['b1']\n",
    "            self.W['W2'] -= lr*grads['W2']\n",
    "            self.W['b2'] -= lr*grads['b2']\n",
    "            print(\"epoch\",epoch,\"==============\",self.loss(x,t),\"accuracy:=============\",self.accuracy(x,t))\n",
    "            self.loss_val.append(np.round(self.loss(x,t)),2)\n",
    "            self.acc_val.append(np.round(self.accuracy(x,t)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5657217-48fe-460b-97f1-ff22fe4c3a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ad58928-3b9a-4883-a129-c1d143af4595",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "epoch 0 ============== 2.302583507336865 accuracy:============= 0.11252857142857142\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list.append() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3416/1448278029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#해석적\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3416/319610.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, x, t)\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"==============\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"accuracy:=============\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list.append() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "%time\n",
    "epochs = 5\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t) #해석적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa83ae6-0a87-462b-abfc-8ca1d4e91734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델3= w을 0으로 줬을 때, 학습을 안함 : 초기값에 0을 곱해서 : 경사소실 \n",
    "plt.plot(np.arange(len(model3.loss_val)),model3.loss_val)\n",
    "plt.plot(np.arange(len(model3.acc_val)),model3.acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea93ce4-d3de-46d5-8ffa-c5dc24977b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet3:     #가중치가1일때\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.Ones((input_size,hidden_size))\n",
    "        self.W['b1'] = np.Ones(hidden_size)\n",
    "        self.W['W2'] = np.Ones((hidden_size,output_size))\n",
    "        self.W['b2'] = np.Ones(output_size)\n",
    "        self.loss_val = []\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "        self.loss_val=[]\n",
    "        self.acc_val=[]\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): #x업데이트\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        # loss = cross_entropy_error(y,t) #미분하려고 구한거(수치적) >> 해석적으로 쓰려고 class만듦 :forwardmax, backwardmax\n",
    "        loss = self.lastLayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def numerical_gradient(self,x,t):\n",
    "        f = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(f, self.W['W1'])\n",
    "        grads['b1'] = numerical_gradient(f, self.W['b1'])\n",
    "        grads['W2'] = numerical_gradient(f, self.W['W2'])\n",
    "        grads['b2'] = numerical_gradient(f, self.W['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t): #backward시켜주는거 #맨 마지막loss부터 거꾸로 #grad(기울기)를 원래 값에서 빼주면 학습이 되는것이기 때문\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout) #미분값\n",
    "        layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout) \n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = sum(y == t)/x.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x,t):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            self.W['W1'] -= lr*grads['W1']\n",
    "            self.W['b1'] -= lr*grads['b1']\n",
    "            self.W['W2'] -= lr*grads['W2']\n",
    "            self.W['b2'] -= lr*grads['b2']\n",
    "            print(\"epoch\",epoch,\"==============\",np.round(self.loss(x,t),3),\"accuracy:=============\",np.round(self.accuracy(x,t)),3)\n",
    "            self.loss_val.append(np.round(self.loss(x,t)),2)\n",
    "            self.acc_val.append(np.round(self.accuracy(x,t)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4924963-c53e-46da-afae-e69dd4fa8ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d46a7-546e-4401-a0a8-327ff1f4f4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time\n",
    "epochs = 1\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t) #해석적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e649b5-d23d-469d-b540-d8753508c014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet3:     #가중치가 2일떄\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.Ones((input_size,hidden_size))*2\n",
    "        self.W['b1'] = np.Ones(hidden_size)*2\n",
    "        self.W['W2'] = np.Ones((hidden_size,output_size))*2\n",
    "        self.W['b2'] = np.Ones(output_size)*2\n",
    "        self.loss_val = []\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "        self.loss_val=[]\n",
    "        self.acc_val=[]\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): #x업데이트\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        # loss = cross_entropy_error(y,t) #미분하려고 구한거(수치적) >> 해석적으로 쓰려고 class만듦 :forwardmax, backwardmax\n",
    "        loss = self.lastLayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def numerical_gradient(self,x,t):\n",
    "        f = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(f, self.W['W1'])\n",
    "        grads['b1'] = numerical_gradient(f, self.W['b1'])\n",
    "        grads['W2'] = numerical_gradient(f, self.W['W2'])\n",
    "        grads['b2'] = numerical_gradient(f, self.W['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t): #backward시켜주는거 #맨 마지막loss부터 거꾸로 #grad(기울기)를 원래 값에서 빼주면 학습이 되는것이기 때문\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout) #미분값\n",
    "        layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout) \n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = sum(y == t)/x.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x,t):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            self.W['W1'] -= lr*grads['W1']\n",
    "            self.W['b1'] -= lr*grads['b1']\n",
    "            self.W['W2'] -= lr*grads['W2']\n",
    "            self.W['b2'] -= lr*grads['b2']\n",
    "            print(\"epoch\",epoch,\"==============\",np.round(self.loss(x,t),3),\"accuracy:=============\",np.round(self.accuracy(x,t)),3)\n",
    "            self.loss_val.append(np.round(self.loss(x,t)),2)\n",
    "            self.acc_val.append(np.round(self.accuracy(x,t)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193da394-6085-4c14-9baf-b34211ee2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40c25c-9524-45dc-8f82-48c5e3fbe7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3.W['W2']            \n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb051a-009d-4d81-a532-4a34b8b66df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet3:     #가중치 작게\n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_decay):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.random.randn(input_size,hidden_size)*weight_decay\n",
    "        self.W['b1'] = np.random.randn(hidden_size)\n",
    "        self.W['W2'] = np.random.randn(hidden_size,output_size)*weight_decay\n",
    "        self.W['b2'] = np.random.randn(output_size)\n",
    "        self.loss_val = []\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "        self.loss_val=[]\n",
    "        self.acc_val=[]\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): #x업데이트\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        # loss = cross_entropy_error(y,t) #미분하려고 구한거(수치적) >> 해석적으로 쓰려고 class만듦 :forwardmax, backwardmax\n",
    "        loss = self.lastLayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def numerical_gradient(self,x,t):\n",
    "        f = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(f, self.W['W1'])\n",
    "        grads['b1'] = numerical_gradient(f, self.W['b1'])\n",
    "        grads['W2'] = numerical_gradient(f, self.W['W2'])\n",
    "        grads['b2'] = numerical_gradient(f, self.W['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t): #backward시켜주는거 #맨 마지막loss부터 거꾸로 #grad(기울기)를 원래 값에서 빼주면 학습이 되는것이기 때문\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout) #미분값\n",
    "        layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout) \n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = sum(y == t)/x.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x,t):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x,t)\n",
    "            self.W['W1'] -= lr*grads['W1']\n",
    "            self.W['b1'] -= lr*grads['b1']\n",
    "            self.W['W2'] -= lr*grads['W2']\n",
    "            self.W['b2'] -= lr*grads['b2']\n",
    "            print(\"epoch\",epoch,\"==============\",np.round(self.loss(x,t),3),\"accuracy:=============\",np.round(self.accuracy(x,t)),3)\n",
    "            self.loss_val.append(np.round(self.loss(x,t)),2)\n",
    "            self.acc_val.append(np.round(self.accuracy(x,t)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe3183f-0cbd-4e7e-a0df-9075944cf76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size,weight_decay)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59044a-dc19-4246-b95c-13956d9e17eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight_decay=0.5            \n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ac29b-9dbb-468e-aed4-82ff4091e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight_decay를 값 높여서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df385a8-2746-4cb6-a66f-85cf96c41462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size,weight_decay) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650ce46-21c9-49ff-9f3e-40ef58ab1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay=1.5            \n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a2371-17b6-4166-85f5-ac999ed9538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs),model3.loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec649a58-d62b-4cf3-9d2d-86ff2767a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet3:     #가중치1주고 자기자신값으로\n",
    "    def __init__(self,input_size,hidden_size,output_size,weight_decay=1.):\n",
    "        self.W = {}\n",
    "        self.W['W1'] = np.random.randn(input_size,hidden_size)*weight_decay\n",
    "        self.W['b1'] = np.random.randn(hidden_size)\n",
    "        self.W['W2'] = np.random.randn(hidden_size,output_size)*weight_decay\n",
    "        self.W['b2'] = np.random.randn(output_size)\n",
    "        self.loss_val = []\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "        self.loss_val=[]\n",
    "        self.acc_val=[]\n",
    "        \n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        for layer in self.layers.values(): #x업데이트\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        # loss = cross_entropy_error(y,t) #미분하려고 구한거(수치적) >> 해석적으로 쓰려고 class만듦 :forwardmax, backwardmax\n",
    "        loss = self.lastLayer.forward(y,t)\n",
    "        return loss\n",
    "\n",
    "    def numerical_gradient(self,x,t):\n",
    "        f = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(f, self.W['W1'])\n",
    "        grads['b1'] = numerical_gradient(f, self.W['b1'])\n",
    "        grads['W2'] = numerical_gradient(f, self.W['W2'])\n",
    "        grads['b2'] = numerical_gradient(f, self.W['b2'])\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def gradient(self,x,t): #backward시켜주는거 #맨 마지막loss부터 거꾸로 #grad(기울기)를 원래 값에서 빼주면 학습이 되는것이기 때문\n",
    "        self.loss(x,t)\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout) #미분값\n",
    "        layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout) \n",
    "            \n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Affine1'].dW\n",
    "        grads['b1'] = self.layers['Affine1'].db\n",
    "        grads['W2'] = self.layers['Affine2'].dW\n",
    "        grads['b2'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self,x,t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y,axis=1)\n",
    "        t = np.argmax(t,axis=1)\n",
    "        acc = sum(y == t)/x.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def fit(self,epochs,lr,x_train,t_train,x_val,t_val):\n",
    "        for epoch in range(epochs):\n",
    "            grads = self.gradient(x_train,t_train)\n",
    "            self.W['W1'] -= lr*grads['W1']\n",
    "            self.W['b1'] -= lr*grads['b1']\n",
    "            self.W['W2'] -= lr*grads['W2']\n",
    "            self.W['b2'] -= lr*grads['b2']\n",
    "            print(\"epoch\",epoch,\"==============validation_loss\",np.round(self.loss(x_val,t_val),3),\"accuracy:============train_loss\",np.round(self.loss(x_val,t_val)),3)\n",
    "            self.loss_val.append(np.round(self.loss(x_val,t_val)),2)\n",
    "            self.acc_val.append(np.round(self.accuracy(x_val,t_val)),2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e3603-5447-4a89-a165-f1382be54e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, t_train, t_val = train_test_split(X,t,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699293c-92ef-4ee0-9eb3-1499a8605b66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = TwoLayerNet3(input_size,hidden_size,output_size,weight_decay) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f830313a-04ac-4961-b89b-36b2f4c6d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "model3.fit(epochs,lr,X_train,t_train,X_val,t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088781e-7712-46c0-8dc3-e8116784e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.accuracy(X_train,t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb3785-8c4b-4678-8867-c3c3ff5a8dcf",
   "metadata": {},
   "source": [
    "## 멀티레이어 해석적 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aef143-229e-4097-bc61-02ededf9e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#멀티레이어 구성하기 \n",
    "#         self.W['W1'] = np.random.randn(input_size,hidden_size[0])\n",
    "#         self.W['b1'] = np.random.randn(hidden_size[1])\n",
    "#         self.W['W2'] = np.random.randn(hidden_size[1],hidden_size[2])\n",
    "#         self.W['b2'] = np.random.randn(hidden_size[2])\n",
    "#         self.W['W3'] = np.random.randn(hidden_size[2],output_size)\n",
    "#         self.W['b3'] = np.random.randn(output_size)\n",
    "        \n",
    "#         self.loss_val = []\n",
    "#         self.layers = OrderedDict()\n",
    "#         self.layers['Affine1'] = Affine(self.W['W1'],self.W['b1'])\n",
    "#         self.layers['Relu1'] = Relu()\n",
    "#         self.layers['Affine2'] = Affine(self.W['W2'],self.W['b2'])\n",
    "#         self.loss_val=[]\n",
    "#         self.acc_val=[]\n",
    "        \n",
    "#         self.lastLayer = SoftmaxWithLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9dae2bd5-51fe-4cd5-bdcb-59b6bf600695",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayer:\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        hidden_size.insert(0,input_size)\n",
    "        hidden_size.append(output_size)\n",
    "        self.W = {}\n",
    "        for i in range(len(hidden_size)-1):\n",
    "            w_key = 'W'+str(i+1)\n",
    "            b_key = 'b'+str(i+1)\n",
    "            self.W[w_key] = np.random.randn(hidden_size[i],hidden_size[i+1])\n",
    "            self.W[b_key] = np.random.randn(hidden_size[i+1])\n",
    "            \n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for i in range(int(len(self.W)/2-1)): #각자 이거는 줄여보기 \n",
    "            j = i*2 \n",
    "            key1 = 'Affine'+str(i+1)\n",
    "            key2 = 'Relu'+str(i+1)\n",
    "            w = list(self.W.keys())[j]\n",
    "            b = list(self.W.keys())[j+1]\n",
    "            self.layers[key1] = Affine(self.W[w],self.W[b])\n",
    "            self.layers[key2] = Relu()\n",
    "        \n",
    "        last_num = str(int(len(self.W)/2))\n",
    "        self.layers['Affine'+last_num] = Affine(self.W['W'+last_num],self.W['b'+last_num])\n",
    "        self.Lastlayer = SoftmaxWithLoss()\n",
    "\n",
    "#     def predict(self,x):\n",
    "#         for layer in self.layers.values():\n",
    "#             x=layer.forward(x) #x=np.dot(x,layer)\n",
    "#         return x\n",
    "        \n",
    "#     def loss(self,x,t):\n",
    "#         y=self.predit(x)\n",
    "#         loss = self.Lastlayer.forward(y,t)\n",
    "#         return loss\n",
    "        \n",
    "#     def gradient(self,x,t): #백워드 가즈아 #마무리는 어파인 #다시짜기\n",
    "#         dout = 1\n",
    "#         dout = self.Lastlayer.backward(dout)\n",
    "#         layers = list(self.layers.values()) #끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\n",
    "#         layers.reverse()\n",
    "#         for layer in layers:\n",
    "#             dout = layer.backward(dout)\n",
    "#         grads = {}\n",
    "#         for key in self.layers.keys():\n",
    "#             if key[:6] == 'Affine':\n",
    "#                 grads[key] = self.layers[key].dW\n",
    "#                 grads[key] = self.layers[key].db\n",
    "#         return grads\n",
    "    \n",
    "    \n",
    "    def predit(self,x):\n",
    "        pass\n",
    "\n",
    "    def loss(self,x,t):\n",
    "        pass\n",
    "\n",
    "    def gradient(self):\n",
    "        pass\n",
    "\n",
    "    def accuracy(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "42157406-0023-45b3-bf4d-2c6aba5b96e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size =3\n",
    "hidden_size = [4,5,6]\n",
    "output_size=7\n",
    "\n",
    "layer_test = MultiLayer(input_size,hidden_size,output_size)\n",
    "\n",
    "X=np.random.randn(10,3)\n",
    "t=np.zeros((10,7))\n",
    "t[:,3]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8db9259a-8dde-4247-b42a-290dfa874eba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Affine1', <layers.Affine at 0x209a1874310>),\n",
       "             ('Relu1', <layers.Relu at 0x209a1874700>),\n",
       "             ('Affine2', <layers.Affine at 0x209a18742e0>),\n",
       "             ('Relu2', <layers.Relu at 0x209a1874100>),\n",
       "             ('Affine3', <layers.Affine at 0x209a18740d0>),\n",
       "             ('Relu3', <layers.Relu at 0x209a1874eb0>),\n",
       "             ('Affine4', <layers.Affine at 0x209a1874ee0>)])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_test.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aae55c1b-30fc-4c30-bb92-90d002299fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W1', 'b1', 'W2', 'b2', 'W3', 'b3', 'W4', 'b4'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_test.W.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e3aa33fc-0902-406e-a7b1-bf098951914c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 2.41544046, -0.40836502,  0.58904597, -1.14441821],\n",
       "        [ 0.28911774, -0.10786884,  1.16548892, -0.02215859],\n",
       "        [-2.3396585 ,  0.68209903, -0.8574301 , -0.62269101]]),\n",
       " 'b1': array([-0.27613138,  2.36283594, -0.58540888,  1.72735181]),\n",
       " 'W2': array([[ 0.26756815,  0.87046703, -0.09813371,  0.29892997,  1.21291999],\n",
       "        [-0.92416493, -0.21488316, -0.98005912,  0.94044104,  1.53190971],\n",
       "        [-0.58811221, -0.3212423 , -0.71504672, -0.27395887, -0.38517284],\n",
       "        [ 0.75678864,  1.07137231,  1.21724987,  0.04421214,  0.99396481]]),\n",
       " 'b2': array([-0.87030517,  1.91427855,  0.08283409,  1.63891152, -0.4743857 ]),\n",
       " 'W3': array([[ 1.2151476 ,  0.44816203,  1.65303103, -0.69858501, -0.27936574,\n",
       "         -0.5685668 ],\n",
       "        [-0.41049719, -0.75843698, -1.48728491, -0.31125352,  0.43829949,\n",
       "          0.06078054],\n",
       "        [ 0.54467193, -1.34972589, -0.18936993, -0.03770713,  0.57041694,\n",
       "         -0.33961103],\n",
       "        [-0.13990459,  0.78025321, -0.12508787, -0.32764181,  2.67665459,\n",
       "          0.78435783],\n",
       "        [ 0.2427898 , -0.20262197,  0.03642117, -0.83492023, -1.44496582,\n",
       "         -0.33508841]]),\n",
       " 'b3': array([ 0.45966137,  0.31580347,  0.23461863,  2.66558355, -0.20567125,\n",
       "        -0.85076422]),\n",
       " 'W4': array([[ 0.28034817, -0.06384122,  1.72192669,  1.28457352,  0.33937993,\n",
       "          0.35281571, -0.14086649],\n",
       "        [-0.46784605, -0.83556442,  1.08276953, -0.81814171,  0.7495099 ,\n",
       "          0.93557472,  0.46652451],\n",
       "        [ 0.22467761, -0.03903031,  0.98745991,  0.42674219, -0.24540057,\n",
       "          0.61514463,  1.72470708],\n",
       "        [-0.35800434,  0.33578669, -0.31296566, -3.10270672,  0.39105454,\n",
       "          0.829287  ,  0.53271668],\n",
       "        [-1.51359408, -1.28628515,  0.8042115 ,  0.62966068,  0.37452185,\n",
       "         -0.71013142,  0.32362868],\n",
       "        [-0.88504695, -0.01772836,  1.15609784,  1.50127672,  1.80967051,\n",
       "         -0.45613049, -0.06280194]]),\n",
       " 'b4': array([ 1.06990214, -0.7833623 , -0.02617114,  0.73314341,  1.23533723,\n",
       "         1.09792132, -0.03131051])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_test.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4237f041-251d-4165-9ede-639593cda48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.70593324, -6.26241257,  3.83474751,  3.98268972,  3.51667661,\n",
       "        -2.09663742,  1.32164424],\n",
       "       [-6.09879279, -6.33657681,  4.28601075,  4.54679997,  4.17637235,\n",
       "        -2.29541565,  1.31651892],\n",
       "       [-8.96829375, -8.95447663,  6.93987203,  5.1500147 ,  6.1226268 ,\n",
       "        -2.47935691,  2.20849124],\n",
       "       [-2.86776057, -3.99798949,  2.1889885 ,  2.57439789,  2.49488786,\n",
       "        -0.75684054,  0.76542738],\n",
       "       [-2.55242401, -3.7940062 ,  1.96167654,  2.34447795,  2.27824854,\n",
       "        -0.60533087,  0.71996659],\n",
       "       [-6.20815849, -6.3985374 ,  4.37305207,  4.64009599,  4.2705362 ,\n",
       "        -2.34845175,  1.32927071],\n",
       "       [-8.40576501, -8.52094572,  6.71172459,  4.99979344,  5.90477909,\n",
       "        -2.24169377,  2.08130295],\n",
       "       [-4.20684038, -5.32149735,  3.11096745,  3.17803986,  2.613864  ,\n",
       "        -1.33832046,  1.08251065],\n",
       "       [-7.91864815, -7.92299751,  5.81133428,  5.08088946,  5.29843819,\n",
       "        -2.60530729,  1.82288582],\n",
       "       [-3.95220218, -5.04608338,  2.64703258,  2.83033751,  2.48920352,\n",
       "        -1.25858235,  1.04071419]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_test.predict(np.random.randn(10,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74c54995-9e8f-4628-9370-5df598d0e89e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/3410749930.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/2627247830.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#백워드 가즈아 #마무리는 어파인 #다시짜기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLastlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#끝까지 계산했다 다시 back해줘야해서 순서 바꾸기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\수업노트\\이강욱강사\\9.DeepLearning\\layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "layer_test.gradient(X,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "abc6f910-619d-409a-9d88-8757b7eb8f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/911554692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLastlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\수업노트\\이강욱강사\\9.DeepLearning\\layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "layer_test.Lastlayer.backward(dout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45ffb73e-63b2-43c6-a312-ff9a4c0f87a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/3271566048.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAffine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlayer_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'b'"
     ]
    }
   ],
   "source": [
    "x=np.random.randn(10,3)\n",
    "layers=OrderedDict()\n",
    "for i in range(int(len(layer_test.W)/2)-1):\n",
    "    # print(i,i+1)\n",
    "    j=i*2\n",
    "    key1 = 'Affine'+str(i+1)\n",
    "    key2 = 'Relu'+str(i+1)\n",
    "    w =  list(layer_test.W.keys())[j]\n",
    "    b =  list(layer_test.W.keys())[j+1]\n",
    "    layers[key1]=Affine(np.dot(x,layer_test.W[w])+layer_test.W[b])\n",
    "    layers[key2]=Relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7b9bd7e4-eb76-4c1e-9607-6ae8676c0247",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lastlayer',\n",
       " 'W',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'fit',\n",
       " 'gradient',\n",
       " 'layers',\n",
       " 'loss',\n",
       " 'predict']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(layer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "14ea3444-8484-46e2-8d3a-20a915a5cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4,)\n",
      "(4, 5)\n",
      "(5,)\n",
      "(5, 6)\n",
      "(6,)\n",
      "(6, 7)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "for i in layer_test.W.keys():\n",
    "    print(layer_test.W[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68e94d-0ac1-4732-b890-b96ca98c1d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
